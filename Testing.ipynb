{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627d4aed-2822-408c-bd91-a102bbf70941",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6078f38-448b-4cb2-8f1d-be74d0ba94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.10.1\n",
      "tensorflow-cloud==0.1.16\n",
      "tensorflow-datasets==4.8.2\n",
      "tensorflow-estimator==2.10.0\n",
      "tensorflow-hub==0.13.0\n",
      "tensorflow-io==0.27.0\n",
      "tensorflow-io-gcs-filesystem==0.27.0\n",
      "tensorflow-metadata==1.11.0\n",
      "tensorflow-probability==0.19.0\n",
      "tensorflow-serving-api==2.10.1\n",
      "tensorflow-transform==1.11.0\n",
      "google-cloud-storage==2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep tensorflow || pip install tensorflow\n",
    "!pip freeze | grep google-cloud-storage || pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b40778b-4997-4a2c-978d-79e17fad434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 13:36:17.965374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 13:36:22.791277: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-01 13:36:33.691403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-01 13:36:33.691672: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-01 13:36:33.691690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks, models\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8734524d-beff-4699-8f19-12dff486f643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT=bf-fpl-pred-080723\n",
      "env: BUCKET=bf-fpl-pred-080723\n",
      "env: REGION=europe-west1\n",
      "env: OUTDIR=gs://bf-fpl-pred-080723/fpl/data\n",
      "env: TFVERSION=2.8\n"
     ]
    }
   ],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT\n",
    "REGION = \"europe-west1\"\n",
    "\n",
    "OUTDIR = f\"gs://{BUCKET}/fpl/data\"\n",
    "\n",
    "%env PROJECT=$PROJECT\n",
    "%env BUCKET=$BUCKET\n",
    "%env REGION=$REGION\n",
    "%env OUTDIR=$OUTDIR\n",
    "%env TFVERSION=2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a34ec2e-8b7a-49c3-890c-91f8e97f496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(tf.version.VERSION)\n",
    "\n",
    "# TODO: Parametrise the column list to use the same package for all positions.\n",
    "CSV_COLUMNS = [\n",
    "    \"hash_id\",\n",
    "    \"element_code\",\n",
    "    \"season_name\",\n",
    "    \"next_season_points\",\n",
    "    \"minutes\",\n",
    "    \"goals_scored\",\n",
    "    \"assists\",\n",
    "    \"clean_sheets\",\n",
    "    \"penalties_missed\",\n",
    "    \"bps\",\n",
    "    \"yellow_threshold\",\n",
    "    \"red_cards\",\n",
    "    \"own_goals\",\n",
    "    \"influence\",\n",
    "    \"creativity\",\n",
    "    \"threat\",\n",
    "    \"start_cost\",\n",
    "    \"end_cost\"\n",
    "]\n",
    "\n",
    "LABEL_COLUMN = \"next_season_points\"\n",
    "DEFAULTS = [\"\", [0.0], \"\", [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]\n",
    "UNWANTED_COLS = [\"hash_id\", \"element_code\", \"season_name\"]\n",
    "\n",
    "INPUT_COLS = [\n",
    "    c for c in CSV_COLUMNS if c != LABEL_COLUMN and c not in UNWANTED_COLS\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb10251-7df0-481e-a52a-7acb610537e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_labels(row_data):\n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        row_data.pop(unwanted_col)\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    return row_data, label\n",
    "\n",
    "\n",
    "def load_dataset(pattern, batch_size, num_repeat):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=pattern,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_COLUMNS,\n",
    "        column_defaults=DEFAULTS,\n",
    "        num_epochs=num_repeat,\n",
    "        shuffle_buffer_size=1000000,\n",
    "    )\n",
    "    return dataset.map(features_and_labels)\n",
    "\n",
    "\n",
    "def create_train_dataset(pattern, batch_size):\n",
    "    dataset = load_dataset(pattern, batch_size, num_repeat=None)\n",
    "    return dataset.prefetch(1)\n",
    "\n",
    "\n",
    "def create_eval_dataset(pattern, batch_size):\n",
    "    dataset = load_dataset(pattern, batch_size, num_repeat=1)\n",
    "    return dataset.prefetch(1)\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "def build_dnn_model(nnsize, lr):\n",
    "    inputs = {\n",
    "        colname: Input(name=colname, shape=(1,), dtype=\"float32\")\n",
    "        for colname in INPUT_COLS\n",
    "    }\n",
    "\n",
    "    # Concatenate numeric inputs\n",
    "    dnn_inputs = Concatenate()(list(inputs.values()))\n",
    "\n",
    "    x = dnn_inputs\n",
    "    for layer, nodes in enumerate(nnsize):\n",
    "        x = Dense(nodes, activation=\"relu\", name=f\"h{layer}\")(x)\n",
    "    output = Dense(1, name=\"next_sason_points\")(x)\n",
    "\n",
    "    model = models.Model(inputs, output)\n",
    "\n",
    "    lr_optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=lr_optimizer, loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate(batch_size, lr, nnsize, eval_data_path, num_evals, num_examples_to_train_on, output_dir, train_data_path):\n",
    "    # TODO 1b\n",
    "    batch_size = batch_size\n",
    "    lr = lr\n",
    "    nnsize = [int(s) for s in nnsize.split()]\n",
    "    eval_data_path = eval_data_path\n",
    "    num_evals = num_evals\n",
    "    num_examples_to_train_on = num_examples_to_train_on\n",
    "    output_dir = output_dir\n",
    "    train_data_path = train_data_path\n",
    "\n",
    "    model_export_path = os.path.join(output_dir, \"savedmodel\")\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "    tensorboard_path = os.path.join(output_dir, \"tensorboard\")\n",
    "\n",
    "    if tf.io.gfile.exists(output_dir):\n",
    "        tf.io.gfile.rmtree(output_dir)\n",
    "\n",
    "    model = build_dnn_model(nnsize, lr)\n",
    "    logging.info(model.summary())\n",
    "\n",
    "    trainds = create_train_dataset(train_data_path, batch_size)\n",
    "    evalds = create_eval_dataset(eval_data_path, batch_size)\n",
    "\n",
    "    steps_per_epoch = num_examples_to_train_on // (batch_size * num_evals)\n",
    "\n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, save_weights_only=True, verbose=1\n",
    "    )\n",
    "    tensorboard_cb = callbacks.TensorBoard(tensorboard_path, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        trainds,\n",
    "        validation_data=evalds,\n",
    "        epochs=num_evals,\n",
    "        steps_per_epoch=max(1, steps_per_epoch),\n",
    "        verbose=2,  # 0=silent, 1=progress bar, 2=one line per epoch\n",
    "        callbacks=[checkpoint_cb, tensorboard_cb],\n",
    "    )\n",
    "\n",
    "    # Exporting the model with default serving function.\n",
    "    model.save(model_export_path)\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0187e8c-13fd-4018-8604-bb90e7593dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " minutes (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " goals_scored (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " assists (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " clean_sheets (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " penalties_missed (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " bps (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " yellow_threshold (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " red_cards (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " own_goals (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " influence (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " creativity (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " threat (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " start_cost (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " end_cost (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 14)           0           ['minutes[0][0]',                \n",
      "                                                                  'goals_scored[0][0]',           \n",
      "                                                                  'assists[0][0]',                \n",
      "                                                                  'clean_sheets[0][0]',           \n",
      "                                                                  'penalties_missed[0][0]',       \n",
      "                                                                  'bps[0][0]',                    \n",
      "                                                                  'yellow_threshold[0][0]',       \n",
      "                                                                  'red_cards[0][0]',              \n",
      "                                                                  'own_goals[0][0]',              \n",
      "                                                                  'influence[0][0]',              \n",
      "                                                                  'creativity[0][0]',             \n",
      "                                                                  'threat[0][0]',                 \n",
      "                                                                  'start_cost[0][0]',             \n",
      "                                                                  'end_cost[0][0]']               \n",
      "                                                                                                  \n",
      " h0 (Dense)                     (None, 32)           480         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " h1 (Dense)                     (None, 8)            264         ['h0[0][0]']                     \n",
      "                                                                                                  \n",
      " next_sason_points (Dense)      (None, 1)            9           ['h1[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 753\n",
      "Trainable params: 753\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Epoch 1: saving model to ./fpl-model/checkpoints\n",
      "20/20 - 4s - loss: 11748.7002 - rmse: 102.6855 - mse: 11748.7002 - val_loss: 12504.1875 - val_rmse: 101.0181 - val_mse: 12504.1875 - 4s/epoch - 185ms/step\n",
      "INFO:tensorflow:Assets written to: ./fpl-model/savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./fpl-model/savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run with 1 eval\n",
    "history = train_and_evaluate(5, 0.001, \"32 8\", \"gs://bf-fpl-pred-080723/fpl/data/mid-test*\", 1, 100, \"./fpl-model\", \"gs://bf-fpl-pred-080723/fpl/data/mid-train*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e57cd-4849-4042-8f77-145529a42f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
